{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bXFr0CdSnvqJ","executionInfo":{"status":"ok","timestamp":1739398644032,"user_tz":0,"elapsed":25344,"user":{"displayName":"F Xu","userId":"09663922277527295904"}},"outputId":"ad60bae9-e30e-43a2-fdf2-be7b62dbc88b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["###Mount data directory for MIMIC\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"code","source":["###Read dataset\n","import pandas as pd\n","from pathlib import Path\n","\n","###init dataset path\n","dataset_dir = Path('/content/gdrive/MyDrive/hackathon/')\n","interim_directory = Path('/content/gdrive/MyDrive/hackathon')\n","\n","cvd_df = pd.read_csv(dataset_dir / \"cvd_note.csv\")\n","\n","column_names = cvd_df.columns\n","print(column_names)\n","\n","###Give a placeholder ID for each text\n","cvd_df.columns.values[0] = 'note_ID'\n","\n","print(cvd_df['note_ID'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C3uaKjJLoCXe","executionInfo":{"status":"ok","timestamp":1739398665065,"user_tz":0,"elapsed":21036,"user":{"displayName":"F Xu","userId":"09663922277527295904"}},"outputId":"801b6ebd-a91f-4d2d-d47b-5044120008ac"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-3-8b5ee534d460>:9: DtypeWarning: Columns (10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n","  cvd_df = pd.read_csv(dataset_dir / \"cvd_note.csv\")\n"]},{"output_type":"stream","name":"stdout","text":["Index(['Unnamed: 0', 'row_id', 'subject_id', 'hadm_id', 'seq_num', 'icd9_code',\n","       'row_id.1', 'subject_id.1', 'hadm_id.1', 'chartdate', 'charttime',\n","       'storetime', 'category', 'description', 'cgid', 'iserror', 'text'],\n","      dtype='object')\n","0              0\n","1              1\n","2              2\n","3              3\n","4              4\n","           ...  \n","364074    364074\n","364075    364075\n","364076    364076\n","364077    364077\n","364078    364078\n","Name: note_ID, Length: 364079, dtype: int64\n"]}]},{"cell_type":"code","source":["###MIMIC headings\n","known_headings = [\n","    \"Name:\",\n","    \"Unit No:\",\n","    \"Admission Date:\",\n","    \"Discharge Date:\",\n","    \"Date of Birth:\",\n","    \"Sex:\",\n","    \"Service:\",\n","    \"Allergies:\",\n","    \"Attending:\",\n","    \"Chief Complaint:\",\n","    \"History of Present Illness:\",\n","    \"Past Medical History:\",\n","    \"Social History:\",\n","    \"Family History:\",\n","    \"Physical Exam:\",\n","    \"Pathology:\",\n","    \"Brief Hospital Course:\",\n","    \"Medications on Admission:\",\n","    \"Discharge Medications:\",\n","    \"Discharge Disposition:\",\n","    \"Discharge Diagnosis:\",\n","    \"Discharge Condition:\",\n","    \"Discharge Instructions:\",\n","    \"Followup Instructions:\",\n","    \"Discharge:\",\n","    \"Pertinent Results:\",\n","    \"Studies:\",\n","    \"Pending Results:\",\n","    \"Transitional Issues:\",\n","    \"PAST SURGICAL HISTORY:\",\n","    \"ADMISSION PHYSICAL EXAM:\",\n","    \"DISCHARGE PHYSICAL EXAM:\",\n","    \"PERTINENT LABS:\",\n","    \"DISCHARGE LABS:\",\n","    \"MICROBIOLOGY:\",\n","    \"IMAGING:\",\n","    \"ACTIVE ISSUES:\",\n","    \"CHRONIC ISSUES:\",\n","    \"Review of Systems:\",\n","    \"Major Surgical or Invasive Procedure:\",\n","    \"ADMISSION CXR:\",\n","    \"FOLLOW UP CXR:\",\n","    \"VASCULAR SURGERY ADMISSION EXAM:\",\n","    \"ADMISSION LABS:\",\n","    \"DEATH EXAM:\",\n","    \"CXR:\",\n","    \"CXR ___:\",\n","    \"SECONDARY:\",\n","    \"LABS:\"\n","]"],"metadata":{"id":"JnEZZqGSpfDw","executionInfo":{"status":"ok","timestamp":1739398665065,"user_tz":0,"elapsed":3,"user":{"displayName":"F Xu","userId":"09663922277527295904"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["###Splitting MIMIC notes by heading\n","import re\n","import numpy as np\n","\n","print(\"Splitting notes and annotations based on subheadings...\")\n","\n","def extract_subsections(x):\n","    section_dict = {}\n","    # for heading in known_headings:\n","    for heading in headings_to_extract:\n","        #print(f\"Extracting subsection for heading: {heading}\")\n","        pattern = r\"(^|\\s\\s+)\" + re.escape(heading)\n","\n","        if not re.search(pattern, x):\n","            continue\n","\n","        match = re.search(pattern, x)\n","\n","        start_index_extract = match.start()\n","\n","        # find closest next section, starting from end of note\n","        next_section_index = len(x) - 1\n","        for next_heading in known_headings:\n","            if next_heading.__eq__(heading):\n","                continue\n","\n","            pattern_next = r\"(^|\\s\\s+)\" + re.escape(next_heading)\n","            match_next = re.search(pattern_next, x)\n","\n","            if not re.search(pattern_next, x):\n","                continue\n","\n","            if next_section_index > match_next.start() > start_index_extract:\n","                next_section_index = match_next.start()\n","\n","        # extract section between start and next section, store\n","        section_dict[heading] = [start_index_extract, next_section_index, x[start_index_extract:next_section_index]]\n","\n","    return section_dict\n","\n","########\n","### parameters to call it\n","########\n","headings_to_extract = [\n","    \"History of Present Illness:\",\n","    \"Medications on Admission:\",\n","    \"Discharge Medications:\"\n","]\n","\n","# do a subset of the notes\n","cvd_subset_df = cvd_df.head(50)\n","\n","# for each note_id, extract sections and save as [note_id | section | section_begin | section_end | section_type]\n","note_ids = cvd_subset_df[\"note_ID\"].unique()\n","\n","# subsections = []\n","subsection_texts = []\n","i=0\n","for note_id in note_ids:\n","    print(f\"Extracting subsection for: {i}th note.\")\n","    text = cvd_subset_df.loc[cvd_subset_df[\"note_ID\"] == note_id, 'text'].item()\n","    subsections_dict = extract_subsections(text)\n","\n","    subnote_text = \"\"\n","\n","    for key in subsections_dict.keys():\n","        start_index = subsections_dict[key][0]\n","        end_index = subsections_dict[key][1]\n","\n","        # concat the text and codes into single entry\n","        subnote_text = subnote_text + subsections_dict[key][2]\n","\n","    # remove duplicate codes and descriptions TODO: optional\n","    subsection_texts.append(subnote_text.lstrip())\n","    i+=1\n","\n","# bring subsection text into dataframe + add ids\n","notes_sections_df = pd.DataFrame(subsection_texts)\n","notes_sections_df.insert(0, \"note_ID\", note_ids)\n","notes_sections_df.columns = ['note_ID', 'text']\n","\n","# remove rows where note did not contain subsections\n","drop_rows = notes_sections_df[notes_sections_df['text']==''].index\n","notes_sections_df.drop(drop_rows, inplace=True)\n","\n","print(notes_sections_df.columns.values)\n","notes_sections_df.to_csv(interim_directory /\"mimic_text_subsections.csv\", index=False,sep = \"\\t\")\n","\n","print(\"NOTES SECT:\")\n","#print(notes_sections_df.iloc[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"87Oxft3ipoh4","executionInfo":{"status":"ok","timestamp":1739398726300,"user_tz":0,"elapsed":4409,"user":{"displayName":"F Xu","userId":"09663922277527295904"}},"outputId":"52f43196-c9eb-4ada-bfe0-687f519bbeea"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Splitting notes and annotations based on subheadings...\n","Extracting subsection for: 0th note.\n","Extracting subsection for: 1th note.\n","Extracting subsection for: 2th note.\n","Extracting subsection for: 3th note.\n","Extracting subsection for: 4th note.\n","Extracting subsection for: 5th note.\n","Extracting subsection for: 6th note.\n","Extracting subsection for: 7th note.\n","Extracting subsection for: 8th note.\n","Extracting subsection for: 9th note.\n","Extracting subsection for: 10th note.\n","Extracting subsection for: 11th note.\n","Extracting subsection for: 12th note.\n","Extracting subsection for: 13th note.\n","Extracting subsection for: 14th note.\n","Extracting subsection for: 15th note.\n","Extracting subsection for: 16th note.\n","Extracting subsection for: 17th note.\n","Extracting subsection for: 18th note.\n","Extracting subsection for: 19th note.\n","Extracting subsection for: 20th note.\n","Extracting subsection for: 21th note.\n","Extracting subsection for: 22th note.\n","Extracting subsection for: 23th note.\n","Extracting subsection for: 24th note.\n","Extracting subsection for: 25th note.\n","Extracting subsection for: 26th note.\n","Extracting subsection for: 27th note.\n","Extracting subsection for: 28th note.\n","Extracting subsection for: 29th note.\n","Extracting subsection for: 30th note.\n","Extracting subsection for: 31th note.\n","Extracting subsection for: 32th note.\n","Extracting subsection for: 33th note.\n","Extracting subsection for: 34th note.\n","Extracting subsection for: 35th note.\n","Extracting subsection for: 36th note.\n","Extracting subsection for: 37th note.\n","Extracting subsection for: 38th note.\n","Extracting subsection for: 39th note.\n","Extracting subsection for: 40th note.\n","Extracting subsection for: 41th note.\n","Extracting subsection for: 42th note.\n","Extracting subsection for: 43th note.\n","Extracting subsection for: 44th note.\n","Extracting subsection for: 45th note.\n","Extracting subsection for: 46th note.\n","Extracting subsection for: 47th note.\n","Extracting subsection for: 48th note.\n","Extracting subsection for: 49th note.\n","['note_ID' 'text']\n","NOTES SECT:\n"]}]}]}